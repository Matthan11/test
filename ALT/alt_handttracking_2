# import cv2
# import mediapipe as mp
# import time

# from vision.user_login import handle_login
# from vision.room_selection import handle_room_selection

# # ================= MediaPipe =================
# mp_hands = mp.solutions.hands
# hands = mp_hands.Hands(
#     max_num_hands=1,
#     min_detection_confidence=0.7,
#     min_tracking_confidence=0.7
# )

# COOLDOWN = 1.2
# last_action_time = 0

# # ================= Finger-Erkennung =================
# def fingers_up(hand):
#     fingers = []

#     # Daumen
#     fingers.append(
#         1 if hand.landmark[4].x < hand.landmark[3].x else 0
#     )

#     # Andere Finger
#     for tip in [8, 12, 16, 20]:
#         fingers.append(
#             1 if hand.landmark[tip].y < hand.landmark[tip - 2].y else 0
#         )

#     return fingers

# def clamp(value):
#     return max(0, min(100, value))

# def detect_handshape(f):
#     if f == [0,0,0,0,0]:
#         return "fist"
#     if f == [1,1,1,1,1]:
#         return "open"
#     if f == [0,1,0,0,0]:
#         return "index"
#     if f == [0,1,1,0,0]:
#         return "index_middle"
#     if f == [1,0,0,0,0]:
#         return "thumb_up"
#     if f == [1,1,0,0,0]:
#         return "thumb_index"
#     if f == [0,0,1,0,0]:
#         return "middle"
#     if f == [0,0,0,0,1]:
#         return "pinky"
#     return "other"

# # ================= Hauptfunktion =================
# cap = cv2.VideoCapture(0)

# def get_gesture_action(current_user, selected_room):
#     global last_action_time

#     ret, frame = cap.read()
#     if not ret:
#         return current_user, selected_room, None

#     frame = cv2.flip(frame, 1)
#     rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
#     result = hands.process(rgb)
#     now = time.time()

#     if result.multi_hand_landmarks and now - last_action_time > COOLDOWN:
#         hand = result.multi_hand_landmarks[0]
#         handshape = detect_handshape(fingers_up(hand))

#         current_user = handle_login(handshape, current_user)
#         selected_room = handle_room_selection(handshape, selected_room, current_user)

#         last_action_time = now
#         return current_user, selected_room, handshape

#     return current_user, selected_room, None
